{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Sentiment analysis (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Pandas Dataframe\n",
    "(.csv with scrapped tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-05 18:23:23+00:00</td>\n",
       "      <td>1544386473914503176</td>\n",
       "      <td>Eddie Munson again, because why not ?\\n\\n#stra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-05 18:23:16+00:00</td>\n",
       "      <td>1544386444889886724</td>\n",
       "      <td>Damn dude, Dustin fucking pulls\\n\\n#strangerth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-05 18:22:49+00:00</td>\n",
       "      <td>1544386333132705792</td>\n",
       "      <td>@strangerwriters This series make‚Äôs a family a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-05 18:22:33+00:00</td>\n",
       "      <td>1544386263066857472</td>\n",
       "      <td>this must be in the history books #strangerthi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-05 18:22:22+00:00</td>\n",
       "      <td>1544386220171710476</td>\n",
       "      <td>Who‚Äôs ready to turn up today? Who‚Äôs finished s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-07-05 18:22:11+00:00</td>\n",
       "      <td>1544386171526070278</td>\n",
       "      <td>Eddie Munson everyone. üî•\\n\\n(My little shitty ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-07-05 18:21:26+00:00</td>\n",
       "      <td>1544385984992870400</td>\n",
       "      <td>Yes it's!\\n#strangerthingsseason4 https://t.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-07-05 18:20:41+00:00</td>\n",
       "      <td>1544385793103388674</td>\n",
       "      <td>@BuffySummerSin @JohnnyLCKai I got this. Stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-07-05 18:18:37+00:00</td>\n",
       "      <td>1544385275194900481</td>\n",
       "      <td>@ScullyDanaXfile Nice to meet you hot stuff. #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-07-05 18:18:19+00:00</td>\n",
       "      <td>1544385197793312770</td>\n",
       "      <td>I‚Äôm really gonna miss uü•≤\\n#strangerthingsseaso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Datetime             Tweet Id  \\\n",
       "0  2022-07-05 18:23:23+00:00  1544386473914503176   \n",
       "1  2022-07-05 18:23:16+00:00  1544386444889886724   \n",
       "2  2022-07-05 18:22:49+00:00  1544386333132705792   \n",
       "3  2022-07-05 18:22:33+00:00  1544386263066857472   \n",
       "4  2022-07-05 18:22:22+00:00  1544386220171710476   \n",
       "5  2022-07-05 18:22:11+00:00  1544386171526070278   \n",
       "6  2022-07-05 18:21:26+00:00  1544385984992870400   \n",
       "7  2022-07-05 18:20:41+00:00  1544385793103388674   \n",
       "8  2022-07-05 18:18:37+00:00  1544385275194900481   \n",
       "9  2022-07-05 18:18:19+00:00  1544385197793312770   \n",
       "\n",
       "                                                Text  \n",
       "0  Eddie Munson again, because why not ?\\n\\n#stra...  \n",
       "1  Damn dude, Dustin fucking pulls\\n\\n#strangerth...  \n",
       "2  @strangerwriters This series make‚Äôs a family a...  \n",
       "3  this must be in the history books #strangerthi...  \n",
       "4  Who‚Äôs ready to turn up today? Who‚Äôs finished s...  \n",
       "5  Eddie Munson everyone. üî•\\n\\n(My little shitty ...  \n",
       "6  Yes it's!\\n#strangerthingsseason4 https://t.co...  \n",
       "7  @BuffySummerSin @JohnnyLCKai I got this. Stand...  \n",
       "8  @ScullyDanaXfile Nice to meet you hot stuff. #...  \n",
       "9  I‚Äôm really gonna miss uü•≤\\n#strangerthingsseaso...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('#strangerthings-tweets_no_filtered.csv')\n",
    "df1 = pd.read_csv('#strangerthingsseason4-tweets_nofiltered.csv')\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Datetime  10000 non-null  object\n",
      " 1   Tweet Id  10000 non-null  int64 \n",
      " 2   Text      10000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 312.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying df cleaned already using twee_cleaner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_csv('df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>no_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-05 18:23:23+00:00</td>\n",
       "      <td>1544386473914503176</td>\n",
       "      <td>Eddie Munson again, because why not ?\\n\\n#stra...</td>\n",
       "      <td>again , because why not ? strangerthingsseason4</td>\n",
       "      <td>again , because why not ? strangerthingsseason4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-05 18:23:16+00:00</td>\n",
       "      <td>1544386444889886724</td>\n",
       "      <td>Damn dude, Dustin fucking pulls\\n\\n#strangerth...</td>\n",
       "      <td>Damn dude , strangerthingsseason4 StrangerThings4</td>\n",
       "      <td>Damn dude , strangerthingsseason4 StrangerThings4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-07-05 18:22:49+00:00</td>\n",
       "      <td>1544386333132705792</td>\n",
       "      <td>@strangerwriters This series make‚Äôs a family a...</td>\n",
       "      <td>This series make ‚Äô s a family around the world...</td>\n",
       "      <td>This series make ‚Äô s a family around the world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-07-05 18:22:33+00:00</td>\n",
       "      <td>1544386263066857472</td>\n",
       "      <td>this must be in the history books #strangerthi...</td>\n",
       "      <td>this must be in the history strangerthingsseason4</td>\n",
       "      <td>this must be in the history strangerthingsseason4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-07-05 18:22:22+00:00</td>\n",
       "      <td>1544386220171710476</td>\n",
       "      <td>Who‚Äôs ready to turn up today? Who‚Äôs finished s...</td>\n",
       "      <td>Who ‚Äô s ready to turn up today ? Who ‚Äô s finis...</td>\n",
       "      <td>Who ‚Äô s ready to turn up today ? Who ‚Äô s finis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2022-07-05 18:22:11+00:00</td>\n",
       "      <td>1544386171526070278</td>\n",
       "      <td>Eddie Munson everyone. üî•\\n\\n(My little shitty ...</td>\n",
       "      <td>everyone . üî• ( My little drawing ) strangerthi...</td>\n",
       "      <td>everyone . fire ( My little drawing ) stranger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2022-07-05 18:21:26+00:00</td>\n",
       "      <td>1544385984992870400</td>\n",
       "      <td>Yes it's!\\n#strangerthingsseason4 https://t.co...</td>\n",
       "      <td>Yes it ' s ! strangerthingsseason4</td>\n",
       "      <td>Yes it ' s ! strangerthingsseason4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2022-07-05 18:20:41+00:00</td>\n",
       "      <td>1544385793103388674</td>\n",
       "      <td>@BuffySummerSin @JohnnyLCKai I got this. Stand...</td>\n",
       "      <td>I got this . Stand aside . strangerthingsseason4</td>\n",
       "      <td>I got this . Stand aside . strangerthingsseason4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2022-07-05 18:18:37+00:00</td>\n",
       "      <td>1544385275194900481</td>\n",
       "      <td>@ScullyDanaXfile Nice to meet you hot stuff. #...</td>\n",
       "      <td>Nice to meet you hot stuff . strangerthingssea...</td>\n",
       "      <td>Nice to meet you hot stuff . strangerthingssea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2022-07-05 18:18:19+00:00</td>\n",
       "      <td>1544385197793312770</td>\n",
       "      <td>I‚Äôm really gonna miss uü•≤\\n#strangerthingsseaso...</td>\n",
       "      <td>I ‚Äô m really miss u ü•≤ strangerthingsseason4</td>\n",
       "      <td>I ‚Äô m really miss u ü•≤ strangerthingsseason4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2022-07-05 18:18:10+00:00</td>\n",
       "      <td>1544385162737512448</td>\n",
       "      <td>Done #strangerthingsseason4 at last!!!!</td>\n",
       "      <td>Done strangerthingsseason4 at last !!!!</td>\n",
       "      <td>Done strangerthingsseason4 at last !!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2022-07-05 18:18:08+00:00</td>\n",
       "      <td>1544385152977195008</td>\n",
       "      <td>reminds me of louis‚Äô walls music video #strang...</td>\n",
       "      <td>me of ‚Äô music video strangerthingsseason4</td>\n",
       "      <td>me of ‚Äô music video strangerthingsseason4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2022-07-05 18:17:30+00:00</td>\n",
       "      <td>1544384992180113410</td>\n",
       "      <td>Well I bawled my eyes out after watching #stra...</td>\n",
       "      <td>Well I my out after watching strangerthingssea...</td>\n",
       "      <td>Well I my out after watching strangerthingssea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2022-07-05 18:16:08+00:00</td>\n",
       "      <td>1544384649618661378</td>\n",
       "      <td>Wow thanks, Eddie! We agree! #strangerthingsse...</td>\n",
       "      <td>Wow thanks , ! We agree ! strangerthingsseason4</td>\n",
       "      <td>Wow thanks , ! We agree ! strangerthingsseason4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2022-07-05 18:15:33+00:00</td>\n",
       "      <td>1544384502734000129</td>\n",
       "      <td>GN everyone üôåüèª . \\nVECNA , art for @HardTimes_...</td>\n",
       "      <td>everyone üôåüèª . , art for strangerthingsseason4 ...</td>\n",
       "      <td>everyone raising hands light skin tone . , art...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                   Datetime             Tweet Id  \\\n",
       "0            0  2022-07-05 18:23:23+00:00  1544386473914503176   \n",
       "1            1  2022-07-05 18:23:16+00:00  1544386444889886724   \n",
       "2            2  2022-07-05 18:22:49+00:00  1544386333132705792   \n",
       "3            3  2022-07-05 18:22:33+00:00  1544386263066857472   \n",
       "4            4  2022-07-05 18:22:22+00:00  1544386220171710476   \n",
       "5            5  2022-07-05 18:22:11+00:00  1544386171526070278   \n",
       "6            6  2022-07-05 18:21:26+00:00  1544385984992870400   \n",
       "7            7  2022-07-05 18:20:41+00:00  1544385793103388674   \n",
       "8            8  2022-07-05 18:18:37+00:00  1544385275194900481   \n",
       "9            9  2022-07-05 18:18:19+00:00  1544385197793312770   \n",
       "10          10  2022-07-05 18:18:10+00:00  1544385162737512448   \n",
       "11          11  2022-07-05 18:18:08+00:00  1544385152977195008   \n",
       "12          12  2022-07-05 18:17:30+00:00  1544384992180113410   \n",
       "13          13  2022-07-05 18:16:08+00:00  1544384649618661378   \n",
       "14          14  2022-07-05 18:15:33+00:00  1544384502734000129   \n",
       "\n",
       "                                                 Text  \\\n",
       "0   Eddie Munson again, because why not ?\\n\\n#stra...   \n",
       "1   Damn dude, Dustin fucking pulls\\n\\n#strangerth...   \n",
       "2   @strangerwriters This series make‚Äôs a family a...   \n",
       "3   this must be in the history books #strangerthi...   \n",
       "4   Who‚Äôs ready to turn up today? Who‚Äôs finished s...   \n",
       "5   Eddie Munson everyone. üî•\\n\\n(My little shitty ...   \n",
       "6   Yes it's!\\n#strangerthingsseason4 https://t.co...   \n",
       "7   @BuffySummerSin @JohnnyLCKai I got this. Stand...   \n",
       "8   @ScullyDanaXfile Nice to meet you hot stuff. #...   \n",
       "9   I‚Äôm really gonna miss uü•≤\\n#strangerthingsseaso...   \n",
       "10            Done #strangerthingsseason4 at last!!!!   \n",
       "11  reminds me of louis‚Äô walls music video #strang...   \n",
       "12  Well I bawled my eyes out after watching #stra...   \n",
       "13  Wow thanks, Eddie! We agree! #strangerthingsse...   \n",
       "14  GN everyone üôåüèª . \\nVECNA , art for @HardTimes_...   \n",
       "\n",
       "                                          tweet_clean  \\\n",
       "0     again , because why not ? strangerthingsseason4   \n",
       "1   Damn dude , strangerthingsseason4 StrangerThings4   \n",
       "2   This series make ‚Äô s a family around the world...   \n",
       "3   this must be in the history strangerthingsseason4   \n",
       "4   Who ‚Äô s ready to turn up today ? Who ‚Äô s finis...   \n",
       "5   everyone . üî• ( My little drawing ) strangerthi...   \n",
       "6                  Yes it ' s ! strangerthingsseason4   \n",
       "7    I got this . Stand aside . strangerthingsseason4   \n",
       "8   Nice to meet you hot stuff . strangerthingssea...   \n",
       "9         I ‚Äô m really miss u ü•≤ strangerthingsseason4   \n",
       "10            Done strangerthingsseason4 at last !!!!   \n",
       "11          me of ‚Äô music video strangerthingsseason4   \n",
       "12  Well I my out after watching strangerthingssea...   \n",
       "13    Wow thanks , ! We agree ! strangerthingsseason4   \n",
       "14  everyone üôåüèª . , art for strangerthingsseason4 ...   \n",
       "\n",
       "                                             no_emoji  \n",
       "0     again , because why not ? strangerthingsseason4  \n",
       "1   Damn dude , strangerthingsseason4 StrangerThings4  \n",
       "2   This series make ‚Äô s a family around the world...  \n",
       "3   this must be in the history strangerthingsseason4  \n",
       "4   Who ‚Äô s ready to turn up today ? Who ‚Äô s finis...  \n",
       "5   everyone . fire ( My little drawing ) stranger...  \n",
       "6                  Yes it ' s ! strangerthingsseason4  \n",
       "7    I got this . Stand aside . strangerthingsseason4  \n",
       "8   Nice to meet you hot stuff . strangerthingssea...  \n",
       "9         I ‚Äô m really miss u ü•≤ strangerthingsseason4  \n",
       "10            Done strangerthingsseason4 at last !!!!  \n",
       "11          me of ‚Äô music video strangerthingsseason4  \n",
       "12  Well I my out after watching strangerthingssea...  \n",
       "13    Wow thanks , ! We agree ! strangerthingsseason4  \n",
       "14  everyone raising hands light skin tone . , art...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to work, although there are certain word desappearinf like 'Eddie', 'die', 'reminds', etc...\n",
    "I'm thinking about checking this line:\n",
    "tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #Remove @ sign,\n",
    "or decapitalize too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the hashtag #LuciferNextlix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input search query to scrape tweets and name csv file\n",
    "# Max recent tweets pulls x amount of most recent tweets from that user\n",
    "text_query = '#LuciferNetflix'\n",
    "count = 10000\n",
    "\n",
    "# Calling function to query X amount of relevant tweets and create a CSV file\n",
    "text_query_to_csv(text_query, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-11 12:30:16+00:00</td>\n",
       "      <td>1447540048132464653</td>\n",
       "      <td>@SPlarinou @Karen0____ @AnaRespectfully But it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-11 12:19:17+00:00</td>\n",
       "      <td>1447537284530720772</td>\n",
       "      <td>@Deckerstar4eva @realutopia68 @AnaRespectfully...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-11 12:11:46+00:00</td>\n",
       "      <td>1447535392350085126</td>\n",
       "      <td>I think I downloaded the wrong #Lucifer https:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-11 11:56:28+00:00</td>\n",
       "      <td>1447531543816286214</td>\n",
       "      <td>I've just watched episode S06 | E10 of Lucifer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-11 11:54:58+00:00</td>\n",
       "      <td>1447531166517637122</td>\n",
       "      <td>I've just watched episode S06 | E07 of Lucifer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-10-11 11:54:11+00:00</td>\n",
       "      <td>1447530970446454791</td>\n",
       "      <td>I've just watched episode S06 | E06 of Lucifer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-10-11 11:43:22+00:00</td>\n",
       "      <td>1447528247256707072</td>\n",
       "      <td>Oct 11: Weapon.\\n\\nHarnessing pain as a weapon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-10-11 11:34:35+00:00</td>\n",
       "      <td>1447526035327787011</td>\n",
       "      <td>I've just watched episode S06 | E01 of Lucifer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-10-11 11:12:13+00:00</td>\n",
       "      <td>1447520407809052673</td>\n",
       "      <td>@SPlarinou @Karen0____ @AnaRespectfully They d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-10-11 11:07:49+00:00</td>\n",
       "      <td>1447519300114395136</td>\n",
       "      <td>now i think is time to put together some angel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Datetime             Tweet Id  \\\n",
       "0  2021-10-11 12:30:16+00:00  1447540048132464653   \n",
       "1  2021-10-11 12:19:17+00:00  1447537284530720772   \n",
       "2  2021-10-11 12:11:46+00:00  1447535392350085126   \n",
       "3  2021-10-11 11:56:28+00:00  1447531543816286214   \n",
       "4  2021-10-11 11:54:58+00:00  1447531166517637122   \n",
       "5  2021-10-11 11:54:11+00:00  1447530970446454791   \n",
       "6  2021-10-11 11:43:22+00:00  1447528247256707072   \n",
       "7  2021-10-11 11:34:35+00:00  1447526035327787011   \n",
       "8  2021-10-11 11:12:13+00:00  1447520407809052673   \n",
       "9  2021-10-11 11:07:49+00:00  1447519300114395136   \n",
       "\n",
       "                                                Text  \n",
       "0  @SPlarinou @Karen0____ @AnaRespectfully But it...  \n",
       "1  @Deckerstar4eva @realutopia68 @AnaRespectfully...  \n",
       "2  I think I downloaded the wrong #Lucifer https:...  \n",
       "3  I've just watched episode S06 | E10 of Lucifer...  \n",
       "4  I've just watched episode S06 | E07 of Lucifer...  \n",
       "5  I've just watched episode S06 | E06 of Lucifer...  \n",
       "6  Oct 11: Weapon.\\n\\nHarnessing pain as a weapon...  \n",
       "7  I've just watched episode S06 | E01 of Lucifer...  \n",
       "8  @SPlarinou @Karen0____ @AnaRespectfully They d...  \n",
       "9  now i think is time to put together some angel...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('#LuciferNetflix-tweets.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1249 entries, 0 to 1248\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Datetime  1249 non-null   object\n",
      " 1   Tweet Id  1249 non-null   int64 \n",
      " 2   Text      1249 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 29.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thus using #LuciferNetflix got me less twitters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\graci\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working, but not cleaning actually\n",
    "\n",
    "\n",
    "#Cleaning Text (RT, Punctuation etc)\n",
    "#Creating new dataframe and new features\n",
    "\n",
    "\n",
    "#tw_list[‚Äútext‚Äù] = tw_list[0]\n",
    "\n",
    "#df['Text'] =tw_list[0] \n",
    "\n",
    "#Removing RT, Punctuation etc\n",
    "def tweet_clean(tweet):\n",
    "    remove_rt = lambda x: re.sub(\"RT @\\w+:\", \"\",x)\n",
    "    rt = lambda x: re.sub(\"(@[A-Za-z0‚Äì9]+)|([‚Å∞-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\"\",x)\n",
    "    return tweet\n",
    "\n",
    "#tw_list['text'] = tw_list.text.map(remove_rt).map(rt)\n",
    "#tw_list['text'] = tw_list.text.str.lower()\n",
    "#tw_list.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_clean = df.copy()\n",
    "#df_clean['tweet_clean_with_Hashtag'] = df_clean['Text'].apply(cleaner)\n",
    "df_tweet_clean['tweet_clean'] = df_tweet_clean['Text'].apply(tweet_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#Lucifer 1x04 Manly Whatnots. \\n\\n‚ÄúWell, it means I shot you. And I'm an idiot, and I'm sorry. And I'm in so much tro‚Ä¶ https://t.co/CnudTwemzR\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet_clean.tweet_clean[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(tweet):\n",
    "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #Remove @ sign\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
    "    tweet = \" \".join(tweet.split())\n",
    "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
    "    tweet = tweet.replace(\"_\", \" \") # sign but keep the text\n",
    "\n",
    "    tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet)\n",
    "         if w.lower() in words or not w.isalpha())\n",
    "    return tweet\n",
    "    \n",
    "#df['tweet_clean'] = df['Text'].apply(cleaner)\n",
    "df_clean = df.copy()\n",
    "#df_clean['tweet_clean_with_Hashtag'] = df_clean['Text'].apply(cleaner)\n",
    "df_clean['tweet_clean_withot_Hashtag'] = df_clean['Text'].apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>tweet_clean_withot_Hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-11 13:02:36+00:00</td>\n",
       "      <td>1447548184696344578</td>\n",
       "      <td>I've just watched episode S06 | E08 of Lucifer...</td>\n",
       "      <td>I ' just watched episode S06 | E08 of !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-11 13:00:01+00:00</td>\n",
       "      <td>1447547537171238917</td>\n",
       "      <td>Lucifer ( @LuciferTheBand ) Share Bloody New M...</td>\n",
       "      <td>( ) Share Bloody New Music Video For ‚Äú Crucifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-11 12:55:45+00:00</td>\n",
       "      <td>1447546462305460226</td>\n",
       "      <td>after 1 hour fighting with my gluegun -.- hope...</td>\n",
       "      <td>after 1 hour fighting with my -.- hope it .. üò©...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-11 12:50:57+00:00</td>\n",
       "      <td>1447545255721504770</td>\n",
       "      <td>#Lucifer 1x04 Manly Whatnots. \\n\\n‚ÄúWell, it me...</td>\n",
       "      <td>1x04 Manly . ‚Äú Well , it I shot you . And I ' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-11 12:45:27+00:00</td>\n",
       "      <td>1447543868841500682</td>\n",
       "      <td>Watching a little #Lucifer on my lunch break a...</td>\n",
       "      <td>Watching a little on my lunch break and this i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Datetime             Tweet Id  \\\n",
       "0  2021-10-11 13:02:36+00:00  1447548184696344578   \n",
       "1  2021-10-11 13:00:01+00:00  1447547537171238917   \n",
       "2  2021-10-11 12:55:45+00:00  1447546462305460226   \n",
       "3  2021-10-11 12:50:57+00:00  1447545255721504770   \n",
       "4  2021-10-11 12:45:27+00:00  1447543868841500682   \n",
       "\n",
       "                                                Text  \\\n",
       "0  I've just watched episode S06 | E08 of Lucifer...   \n",
       "1  Lucifer ( @LuciferTheBand ) Share Bloody New M...   \n",
       "2  after 1 hour fighting with my gluegun -.- hope...   \n",
       "3  #Lucifer 1x04 Manly Whatnots. \\n\\n‚ÄúWell, it me...   \n",
       "4  Watching a little #Lucifer on my lunch break a...   \n",
       "\n",
       "                          tweet_clean_withot_Hashtag  \n",
       "0            I ' just watched episode S06 | E08 of !  \n",
       "1  ( ) Share Bloody New Music Video For ‚Äú Crucifi...  \n",
       "2  after 1 hour fighting with my -.- hope it .. üò©...  \n",
       "3  1x04 Manly . ‚Äú Well , it I shot you . And I ' ...  \n",
       "4  Watching a little on my lunch break and this i...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1945 entries, 0 to 1944\n",
      "Data columns (total 4 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   Datetime                    1945 non-null   object\n",
      " 1   Tweet Id                    1945 non-null   int64 \n",
      " 2   Text                        1945 non-null   object\n",
      " 3   tweet_clean_withot_Hashtag  1945 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 60.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()\n",
    "#df.tweet_clean[4190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1945 entries, 0 to 1944\n",
      "Data columns (total 4 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Datetime                  1945 non-null   object\n",
      " 1   Tweet Id                  1945 non-null   int64 \n",
      " 2   Text                      1945 non-null   object\n",
      " 3   tweet_clean_with_Hashtag  1945 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 60.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()# for df keeping the hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other cleaning possibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emot\n",
      "  Downloading https://files.pythonhosted.org/packages/28/b3/3a0f1f66c448fc66aba69a73d6405a104fd973142594ee8bc5a5122e949c/emot-3.1-py3-none-any.whl (61kB)\n",
      "Installing collected packages: emot\n",
      "Successfully installed emot-3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install emot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'UNICODE_EMO' from 'emot.emo_unicode' (C:\\Users\\graci\\Anaconda3\\lib\\site-packages\\emot\\emo_unicode.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5aaed8c92d9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0memot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memo_unicode\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUNICODE_EMO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEMOTICONS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# Function for converting emoticons into word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconvert_emoticons\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0memot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mEMOTICONS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'('\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0memot\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m')'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEMOTICONS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0memot\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'UNICODE_EMO' from 'emot.emo_unicode' (C:\\Users\\graci\\Anaconda3\\lib\\site-packages\\emot\\emo_unicode.py)"
     ]
    }
   ],
   "source": [
    "from emot.emo_unicode import UNICODE_EMO, EMOTICONS \n",
    "# Function for converting emoticons into word \n",
    "def convert_emoticons(text):    \n",
    "  for emot in EMOTICONS:        \n",
    "    text = re.sub(u'('+emot+')', \"_\".join(EMOTICONS[emot].replace(\",\",\"\").split()), text)    \n",
    "  return text\n",
    "\n",
    "# Pre-processing of the text \n",
    "from tqdm import tqdm  \n",
    "#from bs4 import BeautifulSoup  \n",
    "cleaned_text = []  \n",
    "# tqdm is for printing the status bar \n",
    "for sentance in tqdm(train['text'].values):       \n",
    "#  sentance = re.sub(r\"http\\S+\", \"\", sentance) # remove urls    \n",
    "#  sentance = re.sub('\\[.*?\\]', '', sentance) # Remove square brackets    \n",
    "#  sentance = BeautifulSoup(sentance, 'lxml').get_text() #remove all tags from element    \n",
    "#  sentance = decontracted(sentance)    \n",
    "#  sentance = sentance.replace('***','abusive')     \n",
    "#  sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip() # removes words with numbers       \n",
    "#  sentance = re.sub('[^A-Za-z]+', ' ', sentance)    \n",
    "   sentance = convert_emoticons(sentance)    # https://gist.github.com/sebleier/554280        \n",
    "#  #sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stoplis t)        \n",
    "   cleaned_text.append(sentance.strip())  \n",
    "   train['cleaned_text']=cleaned_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji-translate in c:\\users\\graci\\appdata\\roaming\\python\\python39\\site-packages (0.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from emoji-translate) (1.3.2)\n",
      "Requirement already satisfied: emoji in c:\\users\\graci\\appdata\\roaming\\python\\python39\\site-packages (from emoji-translate) (1.6.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from emoji-translate) (1.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->emoji-translate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->emoji-translate) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->emoji-translate) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 21.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji-translate in c:\\users\\graci\\appdata\\roaming\\python\\python39\\site-packages (0.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from emoji-translate) (1.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from emoji-translate) (1.21.2)\n",
      "Requirement already satisfied: emoji in c:\\users\\graci\\appdata\\roaming\\python\\python39\\site-packages (from emoji-translate) (1.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->emoji-translate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->emoji-translate) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->emoji-translate) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 21.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install emoji-translate --user\n",
    "!pip3 install emoji-translate --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.1.3-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (1.21.2)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.5-cp39-cp39-win_amd64.whl (112 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.4-cp39-cp39-win_amd64.whl (6.5 MB)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Using cached typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting thinc<8.1.0,>=8.0.9\n",
      "  Downloading thinc-8.0.10-cp39-cp39-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (56.0.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (3.0.1)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Using cached wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.1-cp39-cp39-win_amd64.whl (451 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.5-cp39-cp39-win_amd64.whl (21 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.5-cp39-cp39-win_amd64.whl (36 kB)\n",
      "Collecting tqdm<5.0.0,>=4.38.0\n",
      "  Using cached tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Collecting pathy>=0.3.5\n",
      "  Using cached pathy-0.6.0-py3-none-any.whl (42 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp39-cp39-win_amd64.whl (1.9 MB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Using cached spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Using cached smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: typing-extensions, murmurhash, cymem, catalogue, wasabi, typer, srsly, smart-open, pydantic, preshed, blis, tqdm, thinc, spacy-legacy, pathy, spacy\n",
      "Successfully installed blis-0.7.4 catalogue-2.0.6 cymem-2.0.5 murmurhash-1.0.5 pathy-0.6.0 preshed-3.0.5 pydantic-1.8.2 smart-open-5.2.1 spacy-3.1.3 spacy-legacy-3.0.8 srsly-2.4.1 thinc-8.0.10 tqdm-4.62.3 typer-0.4.0 typing-extensions-3.10.0.2 wasabi-0.8.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 21.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version    \n",
      "---------------------------------- -----------\n",
      "-atplotlib                         3.1.1      \n",
      "-cipy                              1.2.1      \n",
      "-illow                             5.4.1      \n",
      "-yproj                             1.9.6      \n",
      "affine                             2.3.0      \n",
      "alabaster                          0.7.12     \n",
      "anaconda-client                    1.7.2      \n",
      "anaconda-navigator                 1.10.0     \n",
      "anaconda-project                   0.8.2      \n",
      "animation                          0.0.7      \n",
      "arcgis                             1.8.0.post1\n",
      "asn1crypto                         0.24.0     \n",
      "astroid                            2.2.5      \n",
      "astropy                            3.1.2      \n",
      "atomicwrites                       1.3.0      \n",
      "attrs                              21.2.0     \n",
      "Babel                              2.6.0      \n",
      "backcall                           0.1.0      \n",
      "backports.os                       0.1.1      \n",
      "backports.shutil-get-terminal-size 1.0.0      \n",
      "basemap                            1.2.0      \n",
      "beautifulsoup4                     4.7.1      \n",
      "bitarray                           0.8.3      \n",
      "bkcharts                           0.2        \n",
      "bleach                             3.1.0      \n",
      "bokeh                              1.0.4      \n",
      "boto                               2.49.0     \n",
      "Bottleneck                         1.2.1      \n",
      "certifi                            2021.5.30  \n",
      "cffi                               1.12.2     \n",
      "chardet                            3.0.4      \n",
      "charset-normalizer                 2.0.4      \n",
      "clang                              5.0        \n",
      "Click                              7.0        \n",
      "click-plugins                      1.1.1      \n",
      "cligj                              0.5.0      \n",
      "cloudpickle                        1.6.0      \n",
      "clyent                             1.2.2      \n",
      "colorama                           0.4.1      \n",
      "comtypes                           1.1.7      \n",
      "conda                              4.10.3     \n",
      "conda-build                        3.17.8     \n",
      "conda-package-handling             1.3.11     \n",
      "conda-verify                       3.1.1      \n",
      "contextlib2                        0.5.5      \n",
      "cryptography                       2.6.1      \n",
      "cycler                             0.10.0     \n",
      "Cython                             0.29.6     \n",
      "cytoolz                            0.9.0.1    \n",
      "dask                               1.1.4      \n",
      "decorator                          4.4.0      \n",
      "defusedxml                         0.5.0      \n",
      "descartes                          1.1.0      \n",
      "distributed                        1.26.0     \n",
      "docutils                           0.14       \n",
      "earthpy                            0.9.1      \n",
      "emoji                              1.6.0      \n",
      "emot                               3.1        \n",
      "entrypoints                        0.3        \n",
      "et-xmlfile                         1.0.1      \n",
      "fastcache                          1.0.2      \n",
      "filelock                           3.0.10     \n",
      "Fiona                              1.8.4      \n",
      "Flask                              1.0.2      \n",
      "flatbuffers                        1.12       \n",
      "fsspec                             0.7.1      \n",
      "future                             0.17.1     \n",
      "gast                               0.4.0      \n",
      "GDAL                               2.3.3      \n",
      "geopandas                          0.6.1      \n",
      "gevent                             1.4.0      \n",
      "glob2                              0.6        \n",
      "greenlet                           0.4.15     \n",
      "h5py                               2.9.0      \n",
      "heapdict                           1.0.0      \n",
      "html5lib                           1.0.1      \n",
      "htmlmin                            0.1.12     \n",
      "idna                               2.8        \n",
      "ImageHash                          4.2.1      \n",
      "imageio                            2.5.0      \n",
      "imagesize                          1.1.0      \n",
      "importlib-metadata                 0.0.0      \n",
      "ipykernel                          5.1.0      \n",
      "ipython                            7.4.0      \n",
      "ipython-genutils                   0.2.0      \n",
      "ipywidgets                         7.5.0      \n",
      "isort                              4.3.16     \n",
      "itsdangerous                       1.1.0      \n",
      "jdcal                              1.4        \n",
      "jedi                               0.13.3     \n",
      "Jinja2                             3.0.1      \n",
      "joblib                             0.14.1     \n",
      "json5                              0.9.4      \n",
      "jsonschema                         3.0.1      \n",
      "jupyter                            1.0.0      \n",
      "jupyter-client                     5.2.4      \n",
      "jupyter-console                    6.0.0      \n",
      "jupyter-core                       4.4.0      \n",
      "jupyterlab                         0.35.4     \n",
      "jupyterlab-server                  0.2.0      \n",
      "keyring                            21.4.0     \n",
      "kiwisolver                         1.0.1      \n",
      "lab                                6.4        \n",
      "lazy-object-proxy                  1.3.1      \n",
      "lerc                               0.1.0      \n",
      "libarchive-c                       2.8        \n",
      "llvmlite                           0.28.0     \n",
      "locket                             0.2.0      \n",
      "lxml                               4.3.2      \n",
      "MarkupSafe                         2.0.1      \n",
      "matplotlib                         3.4.2      \n",
      "matplotlib-venn                    0.11.6     \n",
      "mccabe                             0.6.1      \n",
      "menuinst                           1.4.16     \n",
      "missingno                          0.5.0      \n",
      "mistune                            0.8.4      \n",
      "mkl-fft                            1.0.10     \n",
      "mkl-random                         1.0.2      \n",
      "mock                               4.0.2      \n",
      "more-itertools                     6.0.0      \n",
      "mpmath                             1.1.0      \n",
      "msgpack                            0.6.1      \n",
      "multimethod                        1.4        \n",
      "multipledispatch                   0.6.0      \n",
      "munch                              2.5.0      \n",
      "navigator-updater                  0.2.1      \n",
      "nbconvert                          5.4.1      \n",
      "nbformat                           4.4.0      \n",
      "networkx                           2.6.2      \n",
      "nltk                               3.4        \n",
      "nose                               1.3.7      \n",
      "notebook                           5.7.8      \n",
      "ntlm-auth                          1.4.0      \n",
      "numba                              0.43.1     \n",
      "numexpr                            2.6.9      \n",
      "numpy                              1.21.0     \n",
      "numpydoc                           0.8.0      \n",
      "oauthlib                           3.1.0      \n",
      "olefile                            0.46       \n",
      "opencv-python                      4.2.0.34   \n",
      "openpyxl                           2.6.1      \n",
      "packaging                          19.0       \n",
      "pandas                             1.2.5      \n",
      "pandas-profiling                   3.0.0      \n",
      "pandocfilters                      1.4.2      \n",
      "parso                              0.3.4      \n",
      "partd                              0.3.10     \n",
      "path.py                            11.5.0     \n",
      "pathlib2                           2.3.3      \n",
      "patsy                              0.5.1      \n",
      "pep8                               1.7.1      \n",
      "phik                               0.12.0     \n",
      "pickleshare                        0.7.5      \n",
      "Pillow                             8.3.1      \n",
      "pip                                19.0.3     \n",
      "pkginfo                            1.5.0.1    \n",
      "pluggy                             0.9.0      \n",
      "ply                                3.11       \n",
      "prometheus-client                  0.6.0      \n",
      "prompt-toolkit                     2.0.9      \n",
      "psutil                             5.6.1      \n",
      "py                                 1.8.0      \n",
      "pychalk                            2.0.1      \n",
      "pycodestyle                        2.5.0      \n",
      "pycosat                            0.6.3      \n",
      "pycparser                          2.19       \n",
      "pycrypto                           2.6.1      \n",
      "pycurl                             7.43.0.2   \n",
      "pydantic                           1.8.2      \n",
      "pyflakes                           2.1.1      \n",
      "Pygments                           2.3.1      \n",
      "pylint                             2.3.1      \n",
      "pyodbc                             4.0.26     \n",
      "pyOpenSSL                          19.0.0     \n",
      "pyparsing                          2.3.1      \n",
      "pyproj                             2.6.1.post1\n",
      "pyreadline                         2.1        \n",
      "pyrsistent                         0.14.11    \n",
      "pyshp                              2.1.3      \n",
      "PySocks                            1.6.8      \n",
      "pytesseract                        0.3.8      \n",
      "pytest                             4.3.1      \n",
      "pytest-arraydiff                   0.3        \n",
      "pytest-astropy                     0.5.0      \n",
      "pytest-doctestplus                 0.3.0      \n",
      "pytest-openfiles                   0.3.2      \n",
      "pytest-remotedata                  0.3.1      \n",
      "python-dateutil                    2.8.0      \n",
      "pytz                               2018.9     \n",
      "PyWavelets                         1.0.2      \n",
      "pywin32                            227        \n",
      "pywin32-ctypes                     0.2.0      \n",
      "pywinpty                           0.5.5      \n",
      "PyYAML                             5.1        \n",
      "pyzmq                              18.0.0     \n",
      "QtAwesome                          0.5.7      \n",
      "qtconsole                          4.4.3      \n",
      "QtPy                               1.7.0      \n",
      "rasterio                           1.0.21     \n",
      "requests                           2.26.0     \n",
      "requests-kerberos                  0.12.0     \n",
      "requests-ntlm                      1.1.0      \n",
      "requests-oauthlib                  1.3.0      \n",
      "requests-toolbelt                  0.9.1      \n",
      "rope                               0.12.0     \n",
      "Rtree                              0.8.3      \n",
      "ruamel-yaml                        0.15.46    \n",
      "scikit-image                       0.14.2     \n",
      "scikit-learn                       0.24.2     \n",
      "scipy                              1.7.1      \n",
      "seaborn                            0.11.1     \n",
      "selenium                           3.141.0    \n",
      "Send2Trash                         1.5.0      \n",
      "setuptools                         40.8.0     \n",
      "Shapely                            1.6.4.post1\n",
      "simplegeneric                      0.8.1      \n",
      "simplejson                         3.17.5     \n",
      "singledispatch                     3.4.0.3    \n",
      "six                                1.12.0     \n",
      "sklearn                            0.0        \n",
      "snowballstemmer                    1.2.1      \n",
      "snuggs                             1.4.7      \n",
      "sodapy                             2.1.0      \n",
      "sortedcollections                  1.1.2      \n",
      "sortedcontainers                   2.1.0      \n",
      "soupsieve                          1.8        \n",
      "Sphinx                             1.8.5      \n",
      "sphinxcontrib-applehelp            1.0.2      \n",
      "sphinxcontrib-devhelp              1.0.2      \n",
      "sphinxcontrib-htmlhelp             1.0.3      \n",
      "sphinxcontrib-jsmath               1.0.1      \n",
      "sphinxcontrib-qthelp               1.0.3      \n",
      "sphinxcontrib-serializinghtml      1.1.4      \n",
      "sphinxcontrib-websupport           1.1.0      \n",
      "spyder                             3.3.3      \n",
      "spyder-kernels                     0.4.2      \n",
      "SQLAlchemy                         1.3.1      \n",
      "SRTM.py                            0.3.4      \n",
      "statsmodels                        0.9.0      \n",
      "sympy                              1.3        \n",
      "tables                             3.5.1      \n",
      "tangled-up-in-unicode              0.1.0      \n",
      "tblib                              1.3.2      \n",
      "tensorflow                         2.6.0      \n",
      "terminado                          0.8.1      \n",
      "testpath                           0.4.2      \n",
      "textblob                           0.15.3     \n",
      "threadpoolctl                      2.2.0      \n",
      "toolz                              0.9.0      \n",
      "tornado                            6.0.2      \n",
      "tqdm                               4.62.0     \n",
      "traitlets                          4.3.2      \n",
      "tweepy                             4.1.0      \n",
      "txt2tags                           3.7        \n",
      "typing-extensions                  3.10.0.0   \n",
      "unicodecsv                         0.14.1     \n",
      "urllib3                            1.24.1     \n",
      "visions                            0.7.1      \n",
      "wcwidth                            0.1.7      \n",
      "webencodings                       0.5.1      \n",
      "Werkzeug                           0.14.1     \n",
      "wheel                              0.33.1     \n",
      "widgetsnbextension                 3.5.1      \n",
      "win-inet-pton                      1.1.0      \n",
      "win-unicode-console                0.5        \n",
      "wincertstore                       0.2        \n",
      "winkerberos                        0.7.0      \n",
      "wrapt                              1.11.1     \n",
      "xlrd                               1.2.0      \n",
      "XlsxWriter                         1.1.5      \n",
      "xlwings                            0.15.4     \n",
      "xlwt                               1.3.0      \n",
      "xmltodict                          0.12.0     \n",
      "zict                               0.1.4      \n",
      "zipp                               0.3.3      \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji_translate in c:\\users\\graci\\appdata\\roaming\\python\\python39\\site-packages (0.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from emoji_translate) (1.21.2)\n",
      "Requirement already satisfied: emoji in c:\\users\\graci\\appdata\\roaming\\python\\python39\\site-packages (from emoji_translate) (1.6.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from emoji_translate) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->emoji_translate) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->emoji_translate) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->emoji_translate) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 21.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\graci\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install emoji_translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji_translate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-7bde248e5507>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0memoji_translate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memoji_translate\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTranslator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#from emoji_translate import Translator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'emoji_translate'"
     ]
    }
   ],
   "source": [
    "from emoji_translate.emoji_translate import Translator\n",
    "\n",
    "\n",
    "#from emoji_translate import Translator\n",
    "\n",
    "emo = Translator(exact_match_only=False, randomize=True)\n",
    "\n",
    "print(emo.demojify('The üè† is on üî•!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This works in one direction, from text to emoji, but not the other way around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try \n",
    "!pip install emoji_translate (#with underscore and not minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is fun ‚ù§Ô∏è\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "print(emoji.emojize(\"Python is fun :red_heart:\",variant=\"emoji_type\"))\n",
    "#print(emoji.is_emoji(\"üî•\")) #\"‚ù§Ô∏è\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Series' objects are mutable, thus they cannot be hashed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-5b6cb0cb6c1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mText\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_clean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'no_emoji'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0memoji\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_emoji\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\emoji\\core.py\u001b[0m in \u001b[0;36mis_emoji\u001b[1;34m(string)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mis_emoji\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;34m\"\"\"Returns True if the string is an emoji\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstring\u001b[0m \u001b[1;32min\u001b[0m \u001b[0municode_codes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEMOJI_DATA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1784\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1785\u001b[0m         raise TypeError(\n\u001b[1;32m-> 1786\u001b[1;33m             \u001b[1;34mf\"{repr(type(self).__name__)} objects are mutable, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1787\u001b[0m             \u001b[1;34mf\"thus they cannot be hashed\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1788\u001b[0m         )\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Series' objects are mutable, thus they cannot be hashed"
     ]
    }
   ],
   "source": [
    "df_clean.Text = text\n",
    "df_clean['no_emoji'] = [emoji.is_emoji(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import itertools\n",
    "def extract_emoji(df):\n",
    "    df[\"emoji\"] = \"\"\n",
    "    for index, row in df.iterrows():\n",
    "        for emoji in EMOJIS:\n",
    "            if emoji in row[\"text\"]:\n",
    "                row[\"text\"] = row[\"text\"].replace(emoji, \"\")\n",
    "                row[\"emoji\"] += emoji\n",
    "\n",
    "#extract_emoji(df_clean.Text)\n",
    "#print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\graci\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'iterrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b8337012c5b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mextract_emoji\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mText\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-c16e6243f3c5>\u001b[0m in \u001b[0;36mextract_emoji\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_emoji\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"emoji\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0memoji\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mEMOJIS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0memoji\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5463\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5465\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5467\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "extract_emoji(df.Text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emoji extraction not working for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = TFRobertaModel.from_pretrained('roberta-base')\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='tf')\n",
    "output = model(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "b6f3d4627e7622250b2e6c9fab129b0d70e93af3feb64a41923bd5b6a1b0335d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
